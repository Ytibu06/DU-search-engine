#include "WebPage.h"
#include "Configuration.h"
#include "SplitTool.h"
#include "DirScanner.h"

#include "../include/tinyxml/tinyxml2.h"
#include "../include/simhash/Simhasher.hpp"

#include <iostream>
#include <fstream>
#include <string>
#include <regex>
#include <cstdint>

using std::cerr;
using std::cout;
using std::ifstream;
using std::regex;
using std::regex_replace;
using std::string;

WebPage::WebPage(string &doc, Configuration &config, SplitToolCppJieba &jieba)
: _doc(doc)
{
    //处理文档，每个文档转换成一个网页对象
    processDoc(doc, config, jieba);

    //setSimHash(config,_docContent);

}
// 获取文档id
int WebPage::getDocId() const
{
    return _docId;
}

// 获取文档
string WebPage::getDoc() const
{
    string fmtTXT = string("<doc>\n") +
                  "<docid>" + std::to_string(_docId) + "</docid>\n" +
                  "<url>" + _docUrl + "</url>\n" +
                  "<title>" + _docTitle + "</title>\n" +
                  "<content>" + _docContent + "</content>\n</doc>\n";
    return fmtTXT;
}

// uint64_t WebPage::getSimHash() const
// {
//     return _simHash;
// }

// 文档词频统计map
map<string, int> &WebPage::getWordsMap()
{
    return _wordsMap;
}


// 对文档进行格式化处理，并生成一个文档对象，文章内容交给topK生成词频和topK
void WebPage::processDoc(const string &docString, Configuration &config, SplitToolCppJieba &jieba)
{
    // 获取停用词
    set<string> stopWordList = config.getStopWordList();

    tinyxml2::XMLDocument root;
    root.Parse(docString.c_str());
    if(root.Error()){
        perror("WebPage::processDoc: tinyxml2 parse error");
    }
    tinyxml2::XMLElement *doc = root.FirstChildElement("doc");
    if(doc){
        const char* docIdText = doc->FirstChildElement("docid")->GetText();
        const char* urlText = doc->FirstChildElement("url")->GetText();
        const char* titleText = doc->FirstChildElement("title")->GetText();
        const char* contentText = doc->FirstChildElement("content")->GetText();
        
        _docId = docIdText ? atoi(docIdText) : 0;
        _docUrl = urlText ? urlText : "";
        _docTitle = titleText ? titleText : "";
        _docContent = contentText ? contentText : "";

        // cout << "docId: " << _docId << "\n";
        // cout << "docUrl: " << _docUrl << "\n";
        // cout << "docTitle: " << _docTitle << "\n";
        // cout << "docContent: " << _docContent << "\n";
    }

    vector<string> cutWords = jieba.cut(_docContent);
    calcTopK(cutWords, TOPK_NUMBER, stopWordList);

}

//获取所有词频和topK
void WebPage::calcTopK(vector<string> &wordsVec, int k, set<string> &stopWordList)
{
    // 清空容器
    _wordsMap.clear();

    // 如果不在停用词列表中，自动加入_wordsMap中
    for(auto &keyword : wordsVec){
        if(stopWordList.find(keyword) == stopWordList.end()){
            _wordsMap[keyword]++;
        }
    }

    // 创建词频向量并排序
    vector<pair<string, int>> wordFreqVec(_wordsMap.begin(), _wordsMap.end());
    sort(wordFreqVec.begin(), wordFreqVec.end(), [](const pair<string, int>& a, const pair<string, int>& b) {
        return a.second > b.second; // 按词频降序排列
    });

    
    _topWords.clear();

    // 取前k个高频词
    int count = 0;
    for (auto& pair : wordFreqVec) {
        if (count >= k) break;
        _topWords.push_back(pair.first);
        count++;
    }
    
}

// void WebPage::setSimHash(Configuration &config,const string &docString)
// {
//     map<string,string> simhashPath = config.getConfigMap();
//     string jieba_dict_path = simhashPath["jieba_dict_path"];
//     string hmm_model_path = simhashPath["hmm_model_path"];
//     string idf_path = simhashPath["idf_path"];
//     string stop_words_path = simhashPath["stop_words_path"];

//     simhash::Simhasher simhash(jieba_dict_path, hmm_model_path,idf_path, stop_words_path);
//     string Content = docString;
//     size_t topN = 5;
//     uint64_t Bin = 0;                              // 指纹
//     vector<std::pair<string, double>> keywords; // 生成-- 单词 : 权重
//     simhash.extract(Content, keywords, topN);
//     simhash.make(Content, topN, Bin); // 将指纹的值赋值给 u64
//     _simHash = Bin;

// }

//首字节判断
// size_t WebPage::getByteNum_Utf8(const char byte)
// {
//     int byteNum = 0;
//     for (size_t i = 0; i < 6; ++i)
//     {
//         if (byte & (1 << (7 - i)))
//             ++byteNum;
//         else
//             break;
//     }
//     return byteNum == 0 ? 1 : byteNum;
// }

// 判断两篇文档是否相等
bool operator==(const WebPage &lhs, const WebPage &rhs) 
{
    //return simhash::Simhasher::isEqual(lhs.getSimHash(), rhs.getSimHash());
    int count = 0;
    for(auto &keyword : lhs._topWords){
        if( !(rhs._wordsMap.find(keyword) == rhs._wordsMap.end()) ){
            count++;
        }
    }

    return count >= MAX;
}

// 对文档DocId进行排序
bool operator<(const WebPage &lhs, const WebPage &rhs) 
{
    return lhs._docId < rhs._docId;
}